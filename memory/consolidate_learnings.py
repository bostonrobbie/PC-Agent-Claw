#!/usr/bin/env python3
"""
Memory Consolidation - Organize and index learnings automatically
"""

from pathlib import Path
from datetime import datetime
import json

WORKSPACE = Path(r"C:\Users\User\.openclaw\workspace")
MEMORY_DIR = WORKSPACE / "memory"

def consolidate_learnings():
    """Consolidate and index all learnings"""

    print("=" * 60)
    print("Memory Consolidation")
    print("=" * 60)
    print()

    # Create index of all knowledge
    knowledge_index = {
        'last_updated': datetime.now().isoformat(),
        'domains': {},
        'mistakes': [],
        'successes': [],
        'conversations': []
    }

    # Index knowledge domains
    knowledge_dir = MEMORY_DIR / "knowledge"
    if knowledge_dir.exists():
        for file in knowledge_dir.glob("*.md"):
            domain = file.stem
            with open(file, 'r', encoding='utf-8') as f:
                content = f.read()
                knowledge_index['domains'][domain] = {
                    'file': str(file),
                    'size': len(content),
                    'sections': content.count('##')
                }

    print(f"Indexed {len(knowledge_index['domains'])} knowledge domains")

    # Index learnings
    learnings_dir = MEMORY_DIR / "learnings"
    if learnings_dir.exists():
        mistakes_file = learnings_dir / "mistakes.md"
        if mistakes_file.exists():
            with open(mistakes_file, 'r', encoding='utf-8') as f:
                content = f.read()
                # Extract mistake titles
                for line in content.split('\n'):
                    if line.startswith('## Mistake'):
                        knowledge_index['mistakes'].append(line.replace('## Mistake: ', ''))

        successes_file = learnings_dir / "successes.md"
        if successes_file.exists():
            with open(successes_file, 'r', encoding='utf-8') as f:
                content = f.read()
                for line in content.split('\n'):
                    if line.startswith('## Success'):
                        knowledge_index['successes'].append(line.replace('## Success: ', ''))

    print(f"Indexed {len(knowledge_index['mistakes'])} mistakes")
    print(f"Indexed {len(knowledge_index['successes'])} successes")

    # Index conversations
    conversations_dir = MEMORY_DIR / "conversations"
    if conversations_dir.exists():
        for file in conversations_dir.glob("*.md"):
            knowledge_index['conversations'].append({
                'date': file.stem,
                'file': str(file)
            })

    print(f"Indexed {len(knowledge_index['conversations'])} conversation logs")

    # Save index
    index_file = MEMORY_DIR / "knowledge_index.json"
    with open(index_file, 'w', encoding='utf-8') as f:
        json.dump(knowledge_index, f, indent=2)

    print(f"\nIndex saved: {index_file}")

    # Create quick reference guide
    reference_file = MEMORY_DIR / "QUICK_REFERENCE.md"
    with open(reference_file, 'w', encoding='utf-8') as f:
        f.write("# Quick Reference - Claude's Memory\n\n")
        f.write(f"**Last Updated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write("---\n\n")

        f.write("## Knowledge Domains\n\n")
        for domain, info in knowledge_index['domains'].items():
            f.write(f"- **{domain.replace('-', ' ').title()}:** {info['sections']} sections\n")

        f.write("\n## Recent Mistakes to Avoid\n\n")
        for mistake in knowledge_index['mistakes'][-5:]:  # Last 5
            f.write(f"- {mistake}\n")

        f.write("\n## Recent Successes\n\n")
        for success in knowledge_index['successes'][-5:]:  # Last 5
            f.write(f"- {success}\n")

        f.write("\n## Conversation History\n\n")
        f.write(f"Total conversations logged: {len(knowledge_index['conversations'])}\n")

        f.write("\n---\n\n")
        f.write("*Auto-generated by memory consolidation system*\n")

    print(f"Quick reference: {reference_file}")
    print()
    print("[OK] Memory consolidation complete")

if __name__ == "__main__":
    consolidate_learnings()
